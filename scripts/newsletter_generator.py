import os
import yaml
import markdown
import re
from datetime import datetime, timedelta
from pathlib import Path
import logging
import shutil
from bs4 import BeautifulSoup
from newsletter_template import (
    generate_newsletter_template, 
    generate_archives_template, 
    generate_index_template, 
    generate_latest_template
)

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('newsletter_generator')

def has_valid_frontmatter(file_path):
    """
    V√©rifie si un fichier Markdown a un frontmatter YAML valide.
    
    Retourne :
    - True si un frontmatter valide existe
    - False sinon
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.read()
            
        # V√©rifier la pr√©sence du frontmatter YAML
        if content.startswith('---'):
            # Trouver les d√©limiteurs du frontmatter
            parts = content.split('---', 2)
            if len(parts) >= 3:
                try:
                    # Essayer de parser le frontmatter
                    metadata_yaml = parts[1].strip()
                    yaml.safe_load(metadata_yaml)
                    return True
                except yaml.YAMLError:
                    return False
        return False
    except Exception as e:
        logger.error(f"Erreur lors de la v√©rification du frontmatter pour {file_path}: {e}")
        return False

def get_recent_md_files(docs_directory, processed_files_path, max_count=6, days_ago=30):

    try:
        if not os.path.exists(docs_directory):
            logger.error(f"Le r√©pertoire {docs_directory} n'existe pas")
            return []

        now = datetime.now()
        cutoff_date = now - timedelta(days=days_ago)
        logger.info(f"Date limite pour consid√©rer un fichier comme r√©cent: {cutoff_date}")
        
        # Charger la liste des fichiers d√©j√† trait√©s s'il existe
        processed_files = set()
        if os.path.exists(processed_files_path):
            with open(processed_files_path, 'r') as f:
                processed_files = set(f.read().splitlines())
        logger.info(f"Nombre de fichiers d√©j√† trait√©s: {len(processed_files)}")
        
        # Dictionnaire pour stocker les fichiers s√©lectionn√©s, avec leur chemin comme cl√©
        selected_files = {}
        
        for filename in os.listdir(docs_directory):
            if filename.endswith('.md'):
                file_path = os.path.join(docs_directory, filename)
                file_stats = os.stat(file_path)
                
                # Date de derni√®re modification
                mod_time = datetime.fromtimestamp(file_stats.st_mtime)
                
                # Date de cr√©ation (derni√®re metadata change time)
                create_time = datetime.fromtimestamp(file_stats.st_ctime)
                
                # V√©rifier les diff√©rents crit√®res
                is_new = file_path not in processed_files
                is_recently_created = create_time >= cutoff_date
                is_recently_modified = mod_time >= cutoff_date
                has_frontmatter = has_valid_frontmatter(file_path)
                
                # Crit√®res de s√©lection
                is_selected = (
                    is_new or 
                    is_recently_created or 
                    is_recently_modified or 
                    has_frontmatter
                )
                
                if is_selected:
                    # Ajouter ou mettre √† jour l'entr√©e
                    if file_path not in selected_files:
                        selected_files[file_path] = {
                            'path': file_path,
                            'modified_at': mod_time,
                            'created_at': create_time,
                            'filename': filename,
                            'newly_added': is_new,
                            'recently_created': is_recently_created,
                            'recently_modified': is_recently_modified,
                            'has_frontmatter': has_frontmatter
                        }
        
        # Tri selon les priorit√©s sp√©cifi√©es
        sorted_files = sorted(
            selected_files.values(), 
            key=lambda x: (
                # 1. Priorit√© absolue aux fichiers jamais trait√©s
                not x['path'] in processed_files,
                
                # 2. Puis fichiers cr√©√©s r√©cemment
                not x['recently_created'],
                
                # 3. Puis fichiers modifi√©s r√©cemment
                not x['recently_modified'],
                
                # 4. Puis fichiers avec frontmatter
                not x['has_frontmatter'],
                
                # 5. Par date de cr√©ation d√©croissante
                -x['created_at'].timestamp(),
                
                # 6. Par date de modification d√©croissante
                -x['modified_at'].timestamp()
            ), 
            reverse=True
        )
        
        # Limiter le nombre de fichiers
        recent_files = sorted_files[:max_count]
        logger.info(f"Nombre de fichiers s√©lectionn√©s: {len(recent_files)}")
        
        # Mettre √† jour la liste des fichiers trait√©s
        processed_files.update(file['path'] for file in recent_files)
        
        # Sauvegarder la liste des fichiers trait√©s
        with open(processed_files_path, 'w') as f:
            f.write('\n'.join(processed_files))
        logger.info(f"Liste des fichiers trait√©s sauvegard√©e dans {processed_files_path}")
        
        # Log d√©taill√© des fichiers s√©lectionn√©s
        for file in recent_files:
            logger.info(f"Fichier s√©lectionn√©: {file['filename']}")
            logger.info(f"  - Nouveau: {file['newly_added']}")
            logger.info(f"  - Cr√©√© r√©cemment: {file['recently_created']}")
            logger.info(f"  - Modifi√© r√©cemment: {file['recently_modified']}")
            logger.info(f"  - Avec frontmatter: {file['has_frontmatter']}")
        
        return recent_files
    
    except Exception as e:
        logger.exception(f"Erreur lors de la s√©lection des fichiers r√©cents: {str(e)}")
        return []

def extract_metadata_and_content(md_file_path):
    """
    Extrait les m√©tadonn√©es et le contenu d'un fichier Markdown.
    """
    try:
        with open(md_file_path, 'r', encoding='utf-8') as file:
            content = file.read()

        # V√©rifier la pr√©sence du format frontmatter YAML
        if content.startswith('---'):
            # Trouver les d√©limiteurs du frontmatter
            parts = content.split('---', 2)
            if len(parts) >= 3:
                # Extraire et parser les m√©tadonn√©es
                metadata_yaml = parts[1].strip()
                try:
                    metadata = yaml.safe_load(metadata_yaml)
                    main_content = parts[2].strip()
                    return metadata, main_content
                except yaml.YAMLError as e:
                    logger.error(f"Erreur lors du parsing YAML dans {md_file_path}: {e}")
                    return {}, content
            else:
                logger.warning(f"Format de frontmatter incorrect dans {md_file_path}")
                return {}, content
        else:
            logger.warning(f"Pas de frontmatter trouv√© dans {md_file_path}")
            return {}, content
    except Exception as e:
        logger.error(f"Erreur lors de la lecture du fichier {md_file_path}: {e}")
        return {}, ""

    """
    R√©cup√®re les fichiers Markdown r√©cemment ajout√©s, modifi√©s ou non encore trait√©s.
    
    Am√©liorations:
    - Ne sauvegarde que les fichiers r√©ellement s√©lectionn√©s dans processed_files.txt
    - P√©riode de v√©rification r√©duite √† 30 jours par d√©faut
    - Meilleure logique pour d√©terminer quels fichiers inclure
    """
    try:
        if not os.path.exists(docs_directory):
            logger.error(f"Le r√©pertoire {docs_directory} n'existe pas")
            return []

        now = datetime.now()
        cutoff_date = now - timedelta(days=days_ago)
        logger.info(f"Date limite : {cutoff_date}")
        
        # Charger la liste des fichiers d√©j√† trait√©s s'il existe
        processed_files = set()
        if os.path.exists(processed_files_path):
            with open(processed_files_path, 'r') as f:
                processed_files = set(f.read().splitlines())
        logger.info(f"Nombre de fichiers d√©j√† trait√©s : {len(processed_files)}")
        
        # Liste pour stocker les nouveaux fichiers √† traiter
        md_files = []
        
        # Liste pour suivre les fichiers qui seront s√©lectionn√©s pour cette newsletter
        selected_files_paths = set()
        
        for filename in os.listdir(docs_directory):
            if filename.endswith('.md'):
                file_path = os.path.join(docs_directory, filename)
                file_stats = os.stat(file_path)
                
                logger.debug(f"Traitement du fichier : {file_path}")
                
                # Date de derni√®re modification
                mod_time = datetime.fromtimestamp(file_stats.st_mtime)
                
                # Date de cr√©ation (derni√®re metadata change time)
                create_time = datetime.fromtimestamp(file_stats.st_ctime)
                
                # V√©rifier si le fichier est:
                # 1. Jamais trait√© OU
                # 2. R√©cemment modifi√© OU
                # 3. R√©cemment cr√©√©
                is_new = file_path not in processed_files
                is_recently_modified = mod_time >= cutoff_date
                is_recently_created = create_time >= cutoff_date
                
                if is_new or is_recently_modified or is_recently_created:
                    logger.info(f"Fichier s√©lectionn√©: {filename} - Nouveau: {is_new}, Modifi√© r√©cemment: {is_recently_modified}, Cr√©√© r√©cemment: {is_recently_created}")
                    
                    md_files.append({
                        'path': file_path,
                        'modified_at': mod_time,
                        'created_at': create_time,
                        'filename': filename
                    })
                    
                    # Ajouter ce fichier √† la liste des fichiers s√©lectionn√©s
                    selected_files_paths.add(file_path)
                else:
                    logger.debug(f"Fichier ignor√© : {file_path}")
        
        # Strat√©gie de tri modifi√©e:
        # 1. Priorit√© aux fichiers jamais trait√©s
        # 2. Ensuite par date de cr√©ation d√©croissante
        # 3. Puis par date de modification d√©croissante
        sorted_files = sorted(
            md_files, 
            key=lambda x: (
                x['path'] in processed_files,  # False (nouveaux) avant True (d√©j√† trait√©s)
                -x['created_at'].timestamp(),  # Tri invers√© par timestamp (plus r√©cent d'abord)
                -x['modified_at'].timestamp()
            )
        )
        
        # Limiter au nombre maximum sp√©cifi√©
        recent_files = sorted_files[:max_count]
        
        # Mise √† jour de la liste des fichiers trait√©s - SEULEMENT ceux qui ont √©t√© s√©lectionn√©s
        processed_files.update(selected_files_paths)
        
        # Sauvegarder la liste mise √† jour des fichiers trait√©s
        with open(processed_files_path, 'w') as f:
            f.write('\n'.join(processed_files))
        
        return recent_files
    
    except Exception as e:
        logger.exception(f"Erreur lors de la r√©cup√©ration des fichiers r√©cents : {e}")
        return []

def extract_image_from_content(content):
    """
    Tente d'extraire une URL d'image du contenu Markdown.
    """
    # Chercher les images dans le format markdown ![alt](url)
    image_matches = re.findall(r'!\[(.*?)\]\((.*?)\)', content)
    if image_matches:
        # Prendre la premi√®re image trouv√©e
        return image_matches[0][1]
    
    # Chercher les images en HTML <img src="url">
    html_image_matches = re.findall(r'<img.*?src=[\'"]([^\'"]*)[\'"]', content)
    if html_image_matches:
        return html_image_matches[0]
    
    return None

def find_image_for_project(project_name, content, portfolio_directory):
    """
    Recherche une image pour le projet, en cherchant d'abord dans le contenu puis dans le dossier img.
    """
    # 1. D'abord, chercher dans le contenu du fichier markdown
    image_from_content = extract_image_from_content(content)
    if image_from_content:
        # Si c'est un chemin relatif, le convertir en chemin absolu
        if not image_from_content.startswith(('http://', 'https://')):
            # Supposer que les chemins sont relatifs au dossier img
            image_path = os.path.join(portfolio_directory, "img", os.path.basename(image_from_content))
            if os.path.exists(image_path):
                return image_path
        else:
            # Si c'est une URL, la retourner directement
            return image_from_content
    
    # 2. Ensuite, chercher dans le dossier img par nom de projet
    img_dir = os.path.join(portfolio_directory, "img")
    if os.path.exists(img_dir):
        # Normaliser le nom du projet pour la recherche
        normalized_name = project_name.lower().replace(' ', '-').replace('_', '-')
        
        # Extensions d'image courantes
        image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.svg', '.webp']
        
        # Rechercher par nom exact ou partiel
        for filename in os.listdir(img_dir):
            if any(filename.lower().endswith(ext) for ext in image_extensions):
                name_part = os.path.splitext(filename.lower())[0]
                if normalized_name in name_part or name_part in normalized_name:
                    return os.path.join(img_dir, filename)
        
        # Si aucune correspondance, prendre la premi√®re image
        for filename in os.listdir(img_dir):
            if any(filename.lower().endswith(ext) for ext in image_extensions):
                return os.path.join(img_dir, filename)
    
    # 3. Si aucune image n'est trouv√©e, renvoyer None
    return None

def copy_images_to_newsletter(portfolio_directory, output_directory):
    """
    Copie toutes les images du dossier img du PORTFOLIO vers le dossier img de la newsletter.
    Retourne True si l'image d'en-t√™te existe, False sinon.
    """
    # Chemin vers le dossier img dans le d√©p√¥t PORTFOLIO
    portfolio_img_dir = os.path.join(portfolio_directory, "img")
    
    # Chemin vers le dossier img dans le r√©pertoire de sortie
    output_img_dir = os.path.join(output_directory, "img")
    
    # Variable pour suivre si l'image d'en-t√™te existe
    header_image_exists = False
    
    # Cr√©er le dossier img s'il n'existe pas
    if not os.path.exists(output_img_dir):
        os.makedirs(output_img_dir)
        logger.info(f"Dossier cr√©√©: {output_img_dir}")
    
    # Copier toutes les images
    if os.path.exists(portfolio_img_dir):
        copied_count = 0
        for filename in os.listdir(portfolio_img_dir):
            if any(filename.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif', '.svg', '.webp']):
                src_path = os.path.join(portfolio_img_dir, filename)
                dest_path = os.path.join(output_img_dir, filename)
                try:
                    shutil.copy2(src_path, dest_path)
                    copied_count += 1
                    
                    # V√©rifier si c'est l'image d'en-t√™te
                    if filename == "header-bg.jpg":
                        header_image_exists = True
                        
                except Exception as e:
                    logger.error(f"Erreur lors de la copie de l'image {src_path}: {e}")
        
        logger.info(f"{copied_count} images copi√©es du d√©p√¥t PORTFOLIO vers le dossier newsletter/img")
        
        # Copier l'image d'en-t√™te si elle existe
        header_image_path = os.path.join(portfolio_img_dir, "Slowsia.jpg")
        if os.path.exists(header_image_path):
            header_dest_path = os.path.join(output_img_dir, "header-bg.jpg")
            try:
                shutil.copy2(header_image_path, header_dest_path)
                logger.info(f"Image d'en-t√™te copi√©e: {header_dest_path}")
                header_image_exists = True
            except Exception as e:
                logger.error(f"Erreur lors de la copie de l'image d'en-t√™te: {e}")
        else:
            logger.warning("Image d'en-t√™te 'Slowsia.jpg' non trouv√©e dans le dossier img")
    else:
        logger.warning(f"Dossier d'images non trouv√©: {portfolio_img_dir}")
    
    return header_image_exists



def create_index_and_archives(output_directory, file_date, display_date):
    """
    Cr√©e les fichiers index.html, latest.html et archives.html.
    """
    try:
        # Cr√©er le dossier de sortie s'il n'existe pas
        Path(output_directory).mkdir(parents=True, exist_ok=True)
        
        # Trouver tous les fichiers HTML de newsletter
        html_files = [f for f in os.listdir(output_directory) if f.startswith('newsletter_') and f.endswith('.html')]
        
        # R√©cup√©rer le r√©pertoire parent
        parent_dir = os.path.dirname(output_directory)
        
        # Trier les fichiers par date (du plus r√©cent au plus ancien)
        sorted_files = sorted(html_files, key=lambda f: os.path.getmtime(os.path.join(output_directory, f)), reverse=True)
        
        # La derni√®re newsletter
        latest_file = sorted_files[0] if sorted_files else None
        
        if latest_file:
            # G√©n√©rer et sauvegarder index.html √† la racine
            index_content = generate_index_template(latest_file)
            index_path = os.path.join(parent_dir, "index.html")
            with open(index_path, 'w', encoding='utf-8') as f:
                f.write(index_content)
            logger.info(f"Index.html cr√©√©: {index_path}")
            
            # Cr√©er le fichier .nojekyll
            nojekyll_path = os.path.join(parent_dir, ".nojekyll")
            open(nojekyll_path, 'a').close()
            logger.info(f"Fichier .nojekyll cr√©√©: {nojekyll_path}")
            
            # Copier index.html dans le dossier de sortie
            output_index_path = os.path.join(output_directory, "index.html")
            with open(output_index_path, 'w', encoding='utf-8') as f:
                f.write(index_content)
            
            # G√©n√©rer latest.html
            latest_path = os.path.join(output_directory, "latest.html")
            latest_content = generate_latest_template(os.path.join(output_directory, latest_file))
            with open(latest_path, 'w', encoding='utf-8') as f:
                f.write(latest_content)
            logger.info(f"Latest.html cr√©√©: {latest_path}")
            
            # G√©n√©rer archives.html
            archives_path = os.path.join(output_directory, "archives.html")
            archives_content = generate_archives_template(output_directory)
            with open(archives_path, 'w', encoding='utf-8') as f:
                f.write(archives_content)
            logger.info(f"Archives.html cr√©√©: {archives_path}")
            
            return True
        else:
            logger.warning("Aucune newsletter trouv√©e pour g√©n√©rer les fichiers")
            return False
        
    except Exception as e:
        logger.error(f"Erreur lors de la cr√©ation des fichiers index et archives: {e}")
        return False
def debug_log_portfolio_files(portfolio_directory):
    """
    Fonction de d√©bogage pour logger les d√©tails des fichiers du portfolio.
    """
    docs_directory = os.path.join(portfolio_directory, 'docs')
    
    logger.info("=== D√âBOGAGE : CONTENU DU R√âPERTOIRE DOCS ===")
    logger.info(f"Chemin absolu du r√©pertoire docs: {os.path.abspath(docs_directory)}")
    
    try:
        # Lister tous les fichiers
        all_files = os.listdir(docs_directory)
        logger.info(f"Tous les fichiers dans docs: {all_files}")
        
        # D√©tails des fichiers Markdown
        md_files = [f for f in all_files if f.endswith('.md')]
        logger.info(f"Fichiers Markdown trouv√©s: {md_files}")
        
        # Informations d√©taill√©es sur chaque fichier Markdown
        for filename in md_files:
            file_path = os.path.join(docs_directory, filename)
            file_stats = os.stat(file_path)
            
            logger.info(f"Fichier: {filename}")
            logger.info(f"  Chemin complet: {file_path}")
            logger.info(f"  Taille: {file_stats.st_size} octets")
            logger.info(f"  Derni√®re modification: {datetime.fromtimestamp(file_stats.st_mtime)}")
    
    except Exception as e:
        logger.error(f"Erreur lors du d√©bogage : {e}")
        
def additional_debug():
    """
    Fonction pour des logs de d√©bogage suppl√©mentaires.
    """
    logger.info("=== D√âBOGAGE : INFORMATIONS SUPPL√âMENTAIRES ===")
    logger.info(f"R√©pertoire de travail courant: {os.getcwd()}")
    logger.info(f"Environnement PORTFOLIO_DIR: {os.environ.get('PORTFOLIO_DIR', 'Non d√©fini')}")
    logger.info(f"Environnement OUTPUT_DIR: {os.environ.get('OUTPUT_DIR', 'Non d√©fini')}")

def main():
    """
    Fonction principale du g√©n√©rateur de newsletter.
    """
    logger.info("=== D√âBUT DE LA G√âN√âRATION DE LA NEWSLETTER ===")
    
    # Configuration des chemins
    portfolio_directory = os.environ.get('PORTFOLIO_DIR', '../portfolio')
    docs_directory = os.path.join(portfolio_directory, 'docs')
    output_directory = os.environ.get('OUTPUT_DIR', './newsletters')
    tracking_directory = os.environ.get('TRACKING_DIR', os.path.dirname(__file__))
    
    # Pr√©paration des r√©pertoires
    os.makedirs(tracking_directory, exist_ok=True)
    processed_files_path = os.path.join(tracking_directory, 'processed_files.txt')
    
    # Configuration des dates
    display_date = datetime.now().strftime("%d/%m/%Y")
    file_date = datetime.now().strftime("%Y%m%d")
    
    # Logs de d√©bogage
    logger.info(f"R√©pertoire portfolio: {portfolio_directory}")
    logger.info(f"R√©pertoire docs: {docs_directory}")
    logger.info(f"R√©pertoire de sortie: {output_directory}")
    
    # Copie des images
    header_image_exists = copy_images_to_newsletter(portfolio_directory, output_directory)
    
    # R√©cup√©ration des fichiers Markdown r√©cents
    recent_files = get_recent_md_files(docs_directory, processed_files_path)
    
    if not recent_files:
        logger.warning("Aucun fichier r√©cent trouv√©")
        return False
    
    # Pr√©paration des projets
    projects = []
    for file_info in recent_files:
        try:
            metadata, content = extract_metadata_and_content(file_info['path'])
            
            # Extraction des m√©tadonn√©es
            title = metadata.get('title', os.path.splitext(file_info['filename'])[0])
            description = metadata.get('description', '')
            tags = metadata.get('tags', [])
            url = metadata.get('url', '')
            
            # Recherche et copie de l'image
            image_path = find_image_for_project(title, content, portfolio_directory)
            image_filename = os.path.basename(image_path) if image_path else ""
            
            if image_path and os.path.exists(image_path):
                output_img_dir = os.path.join(output_directory, "img")
                os.makedirs(output_img_dir, exist_ok=True)
                output_image_path = os.path.join(output_img_dir, image_filename)
                shutil.copy2(image_path, output_image_path)
            
            # Chemin de l'image
            image_rel_path = f"img/{image_filename}" if image_filename else \
                f"https://via.placeholder.com/600x400?text={title.replace(' ', '+')}"
            
            # Ajout du projet
            projects.append({
                'title': title,
                'description': description,
                'content': content,
                'tags': tags,
                'url': url,
                'image': image_rel_path,
                'filename': file_info['filename'],
                'path': file_info['path'],
                'id': f"project-{os.path.splitext(file_info['filename'])[0]}"
            })
        
        except Exception as e:
            logger.error(f"Erreur lors du traitement du fichier {file_info['filename']}: {e}")
    
    # G√©n√©ration de la newsletter
    if not projects:
        logger.warning("Aucun projet trouv√© pour g√©n√©rer la newsletter")
        return False
    
    try:
        # G√©n√©ration du contenu HTML
        html_content = generate_newsletter_template(projects, display_date, header_image_exists)
        
        # Nom et chemin des fichiers
        html_filename = f"newsletter_{file_date}.html"
        html_path = os.path.join(output_directory, html_filename)
        
        # Sauvegarde du HTML
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        logger.info(f"Newsletter HTML g√©n√©r√©e : {html_path}")
        
        
        # Conversion et sauvegarde du Markdown LinkedIn
        markdown_linkedin_content = convert_html_to_linkedin_markdown(html_content)
        if markdown_linkedin_content:
            markdown_linkedin_filename = f"newsletter_{file_date}_linkedin.md"
            markdown_linkedin_path = os.path.join(output_directory, markdown_linkedin_filename)
            
            with open(markdown_linkedin_path, 'w', encoding='utf-8') as f:
                f.write(markdown_linkedin_content)
            logger.info(f"Newsletter LinkedIn Markdown g√©n√©r√©e : {markdown_linkedin_path}")
        
        # Cr√©ation des fichiers d'index
        if os.environ.get('CREATE_INDEX', 'true').lower() == 'true':
            create_index_and_archives(output_directory, file_date, display_date)
        
        logger.info("G√©n√©ration de la newsletter termin√©e avec succ√®s")
        return True
    
    except Exception as e:
        logger.error(f"Erreur lors de la g√©n√©ration de la newsletter : {e}")
        return False

def convert_html_to_markdown(html_content):
    """
    Convertit un contenu HTML en Markdown.
    """
    import html2text
    
    h = html2text.HTML2Text()
    h.ignore_links = False
    h.ignore_images = False
    h.body_width = 0  # Ne pas couper les lignes
    
    markdown_text = h.handle(html_content)
    return markdown_text

def convert_html_to_linkedin_markdown(html_content):
    """
    Convertit le contenu HTML en Markdown optimis√© pour LinkedIn
    avec une mise en page structur√©e et des tirets
    """
    try:
        from bs4 import BeautifulSoup
        
        soup = BeautifulSoup(html_content, 'html.parser')
        projects = []
        
        # Emojis correspondant aux types de projets courants
        project_emojis = {
            "data": "üìä", "approche": "üé®", "patrimoine": "üèõÔ∏è", 
            "avatar": "ü§ñ", "ecriture": "‚úçÔ∏è", "fleur": "üå∏", 
            "creation": "üé®", "visualisation": "üìä", "analyse": "üìà", 
            "culture": "üé≠", "documentation": "üìù", "intelligence": "üß†"
        }
        
        # Trouver tous les projets d√©taill√©s
        project_elements = soup.select('.project-full-content')
        
        for project_elem in project_elements:
            # Extraire titre et sous-titres
            title = project_elem.h2.text.strip() if project_elem.h2 else ""
            
            # Trouver les diff√©rentes sections
            sections = {}
            current_section = None
            
            for elem in project_elem.find_all(['h1', 'h2', 'h3', 'p', 'ul', 'ol']):
                if elem.name in ['h1', 'h2', 'h3']:
                    current_section = elem.text.strip()
                    sections[current_section] = []
                elif current_section and elem.name in ['p', 'ul', 'ol']:
                    # Pour les paragraphes et listes
                    if elem.name == 'p':
                        sections[current_section].append(('paragraph', elem.text.strip()))
                    elif elem.name == 'ul':
                        list_items = [('bullet', li.text.strip()) for li in elem.find_all('li')]
                        sections[current_section].extend(list_items)
                    elif elem.name == 'ol':
                        list_items = [('numbered', li.text.strip()) for li in elem.find_all('li')]
                        sections[current_section].extend(list_items)
            
            # Image du projet
            img_elem = project_elem.select_one('.hero-image')
            image = img_elem.get('src', '') if img_elem else ''
            
            # D√©terminer emoji
            emoji = next((emoji for keyword, emoji in project_emojis.items() 
                          if keyword.lower() in title.lower()), "üìå")
            
            projects.append({
                'title': title,
                'image': image,
                'sections': sections,
                'emoji': emoji
            })
        
        # G√©n√©rer le markdown
        markdown = f"# üì∞ Newsletter Portfolio - {datetime.now().strftime('%d/%m/%Y')}\n\n"
        markdown += "## R√©cits visuels, horizons num√©riques : Un voyage entre cr√©ativit√© et innovation üöÄ\n\n"
        markdown += "---\n\n"
        
        for project in projects:
            # Titre du projet avec emoji
            markdown += f"### {project['emoji']} {project['title']}\n\n"
            
            # Image si disponible
            if project['image']:
                markdown += f"![{project['title']}]({project['image']})\n\n"
            
            # Parcourir les sections
            for section, content in project['sections'].items():
                # Titre de section
                markdown += f"#### {section}\n\n"
                
                # Contenu de la section
                for item_type, item in content:
                    if item_type == 'paragraph':
                        markdown += f"{item}\n\n"
                    elif item_type == 'bullet':
                        markdown += f"- {item}\n"
                    elif item_type == 'numbered':
                        markdown += f"1. {item}\n"
                
                # Ajouter un saut de ligne apr√®s chaque section
                markdown += "\n"
            
            # S√©parateur entre les projets
            markdown += "---\n\n"
        
        # Philosophie et conclusion
        markdown += "## üí° Philosophie de l'Innovation\n\n"
        markdown += "> \"L'innovation na√Æt √† l'intersection des disciplines, l√† o√π la cr√©ativit√© rencontre la technologie.\"\n\n"
        
        # Section de contact
        markdown += "## üì± Restons connect√©s !\n\n"
        markdown += "**Envie d'explorer de nouveaux horizons num√©riques ?**\n\n"
        markdown += "‚Äî [Portfolio Complet](https://portfolio-af-v2.netlify.app/)  \n"
        markdown += "‚Äî [Me Contacter sur LinkedIn](https://www.linkedin.com/in/alexiafontaine)\n\n"
        
        # Hashtags
        markdown += "#Innovation #TechCreative #DataScience #DigitalTransformation #CreativeTech\n\n"
        
        markdown += f"¬© {datetime.now().year} Alexia Fontaine - Tous droits r√©serv√©s"
        
        return markdown
    
    except Exception as e:
        logger.error(f"Erreur lors de la conversion LinkedIn Markdown: {e}")
        return None

if __name__ == "__main__":
    main()